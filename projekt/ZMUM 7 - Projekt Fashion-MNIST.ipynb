{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasyfikacja Fashion-MNIST\n",
    "\n",
    "Teraz Twoja kolej na zbudowanie i wytrenowanie sieci neuronowej. Będziesz korzystać z [zestawu danych Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist), zastępującego zbiór danych MNIST. Klasyfikacja zbioru MNIST przy wykorzystaniu NN jest zadaniem trywialnym, w którym można łatwo osiągnąć dokładność lepszą niż 97%. Fashion-MNIST to zestaw obrazów ubrań w skali szarości o wymiarach 28x28. Jest bardziej złożony niż MNIST, więc lepiej odzwierciedla rzeczywistą wydajność sieci i lepiej przedstawia zestawy danych, używane w świecie rzeczywistym. \n",
    "\n",
    "<img src='assets/fashion-mnist-sprite.png' width=500px>\n",
    "\n",
    "W tym notatniku zbudujesz własną sieć neuronową. W większości przypadków możesz po prostu skopiować i wkleić kod z ZMUM 6, ale takie postępowanie nie poprawi Twojej umiejętności tworzenia modeli. Ważne jest, aby samodzielnie napisać kod i sprawić by zadziałał. Warto na pewno zapoznania się z poprzednimi notatnikami podczas pracy nad tym.\n",
    "\n",
    "Na początku załadujmy zbiór danych przez torchvision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:10:26.586668118Z",
     "start_time": "2024-12-01T22:10:26.235742448Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m nn\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m datasets, transforms\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import helper\n",
    "\n",
    "# Zdefiniowanie przekształceń w celu normalizacji danych\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "# Pobranie i wcztanie zbioru treningowego\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Pobranie i wcztanie zbioru testowego\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutaj może modejrzeć jedno ze zdjęć."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-01T22:10:26.257646539Z"
    }
   },
   "outputs": [],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "helper.imshow(image[0, :]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Budowanie sieci\n",
    "\n",
    "W poniższym bloku należy zdefiniować architekturę swojej sieci. Podobnie jak w przypadku MNIST, każdy obraz ma wymiary 28x28, co daje w sumie 784 piksele i należy do 1 z 10 klas. Należy utworzyć co najmniej jedną ukrytą warstwę. Sugeruję użycie funkcji aktywacji ReLU dla warstw ukrytych i zwrócenie na wyjściu logitów lub log-softmax. Od Ciebie zależy, ile dodasz warstw oraz ich rozmiar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-01T22:10:26.257744662Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Zdefiniuj architekturę sieci \n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 10),\n",
    "                      nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trenowanie sieci\n",
    "\n",
    "Teraz należy opracować własną sieć i ją wytrenować. Najpierw trzeba zdefiniować [kryterium](http://pytorch.org/docs/master/nn.html#loss-functions) (coś jak `nn.CrossEntropyLoss`) i [optymalizator](http://pytorch.org/docs/master/optim.html) (zazwyczaj `optim.SGD` lub `optim.Adam`).\n",
    "\n",
    "Następnie napisz kod uczący:\n",
    "\n",
    "* Przepuszczenie obrazów przez sieć w celu uzyskania logitów\n",
    "* Użycie logitów, do wyznaczenia straty\n",
    "* Wykonaj propagacji wstecznej za pomocą `loss.backward()`, w celu wyznaczenia gradientów\n",
    "* Wykonanie kroku optymalizatorem, w celu aktualizacji wagi\n",
    "\n",
    "Dostosowując hiperparametry (ukryte warstwy, tempo uczenia się itp.), powinno uzyskać się `trening loss` poniżej 0,4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-01T22:10:26.257789244Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# TODO: Utwórz sieć, zdefiniuj kryterium i optymalizator \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-01T22:10:26.266028265Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m e \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[1;32m      4\u001B[0m     running_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m----> 5\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m images, labels \u001B[38;5;129;01min\u001B[39;00m \u001B[43mtrainloader\u001B[49m:\n\u001B[1;32m      6\u001B[0m         images \u001B[38;5;241m=\u001B[39m images\u001B[38;5;241m.\u001B[39mview(images\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m      7\u001B[0m         optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'trainloader' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: Trenowanie sieci\n",
    "epochs = 10\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss / len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-01T22:10:26.270182828Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "img = images[0]\n",
    "img = img.resize_(1, 784)\n",
    "\n",
    "# TODO: Oblicz prawdopodobieństwa klas (f. softmax) dla img \n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "ps = torch.exp(logps)\n",
    "\n",
    "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencja i Walidacja\n",
    "\n",
    "Teraz, gdy masz wytrenowaną sieć, możesz jej używać do przewidywania. Zwykle nazywa się to **inferencją**/**wnioskowaniem**, terminem zapożyczonym ze statystyk. Jednak sieci neuronowe mają tendencję do *zbyt dobrego* działania na danych uczących i nie są w stanie uogólniać danych, których wcześniej nie widziały. Nazywa się to **przeuczeniem** *(ang. overfitting)* i ma negatywny wpływ na wydajność wnioskowania. Aby przetestować nadmierne dopasowanie podczas treningu, mierzymy wydajność na danych, które nie znajdują się w zestawie treningowym, zwanym zestawem **walidacyjnym**. Nadmiernego dopasowania unikamy poprzez zastosowanie regularyzacji, jak np. dropout oraz poprzez monitorowanie wydajności walidacji podczas treningu. W tym notatniku zobaczymy, jak to zrobić w PyTorch.\n",
    "\n",
    "Jak zwykle zacznijmy od załadowania zestawu danych przez torchvision. Tym razem skorzystamy z zestawu testowego, który można uzyskać, ustawiając `train=False` tutaj:\n",
    "\n",
    "```python\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "```\n",
    "\n",
    "Zestaw testowy zawiera obrazy, podobnie jak zestaw uczący. Zazwyczaj 10-20% oryginalnego zestawu danych przeznacza się do testowania i walidacji, a reszta wykorzystywana jest do trenowania.\n",
    "\n",
    "Celem walidacji jest zmierzenie wydajności modelu na danych, które nie są częścią zestawu szkoleniowego. Wydajność tutaj zależy jednak od programisty. Zazwyczaj jest to tylko dokładność *(ang. accuracy)*, czyli procent klas, które sieć przewidziała poprawnie. Inne opcje to [precyzja i czułość](https://en.wikipedia.org/wiki/Precision_and_recall#Definition_(classification_context)) oraz wskaźnik błędów 5 największych *(ang. top-5 error rate)*. W tym zadaniu skoncentrujemy się na dokładności. Najpierw zrobimy propagację w przód jedną partią danych testowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-01T22:10:26.270248532Z"
    }
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "images, labels = next(iter(testloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "with torch.no_grad():\n",
    "    ps = torch.exp(model(images))\n",
    "print(ps.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z prawdopodobieństw możemy uzyskać najbardziej prawdopodobną klasę za pomocą metody `ps.topk`. Zwraca to najwyższe wartości $k$. Ponieważ chcemy tylko najbardziej prawdopodobnej klasy, możemy użyć `ps.topk(1)`. Zwraca krotkę wartości górnych $k$ i indeksów górnych $k$. Jeśli najwyższą wartością jest piąty element, otrzymamy 4 jako indeks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-01T22:10:26.270286590Z"
    }
   },
   "outputs": [],
   "source": [
    "top_p, top_class = ps.topk(1, dim=1)\n",
    "print(top_class[:10, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz możemy sprawdzić czy przewidywane klasy pasują do etykiet. Można to łatwo zrobić, porównując `top_class` i `labels`, ale musimy uważać na kształty. Tutaj `top_class` to tensor 2D o kształcie `(64, 1)`, podczas gdy `labels` to 1D z kształtem `(64)`. Aby równość działała tak, jak chcemy, `top_class` i `labels` muszą mieć ten sam kształt.\n",
    "\n",
    "Jeśli zrobimy\n",
    "\n",
    "```python\n",
    "equals = top_class == labels\n",
    "```\n",
    "\n",
    "`equals` będzie miał kształt `(64, 64)`, spróbuj samodzielnie. W efekcie zwraca porównanie jednego elementu w każdym wierszu `top_class` z każdym elementem `labels`, co zwraca 64 wartości logiczne True/False dla każdego wiersza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-01T22:10:26.276445143Z"
    }
   },
   "outputs": [],
   "source": [
    "equals = top_class.squeeze() == labels\n",
    "equals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz musimy obliczyć procent poprawnych prognoz. `equals` przyjmuje wartości binarne: 0 lub 1. Oznacza to, że jeśli po prostu zsumujemy wszystkie wartości i podzielimy przez liczbę wartości, otrzymamy procent poprawnych przewidywań. Jest to ta sama operacja, co wyznaczanie średniej, więc dokładność możemy uzyskać za pomocą wywołania `torch.mean`. Jeśli jednak spróbujesz `torch.mean(equals)`, dostaniesz błąd\n",
    "\n",
    "```\n",
    "RuntimeError: mean is not implemented for type torch.ByteTensor\n",
    "```\n",
    "\n",
    "Dzieje się tak, ponieważ `equals` ma typ `torch.ByteTensor`, a `torch.mean` nie jest zaimplementowany dla tensorów tego typu. Musimy więc przekonwertować `equals` na float tensor. Zauważ, że kiedy bierzemy `torch.mean` zwraca on tensor skalarny, aby uzyskać rzeczywistą wartość jako zmiennoprzecinkową, musimy wykonać `accuracy.item()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-01T22:10:26.276533261Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "print(f'Accuracy: {accuracy.item() * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sieć która nie została wytrenowana zwraca nam wyniki losowe, a jej dokładność powinna wynosić około 10%. Teraz wytrenujmey naszą sieć i dołączając proces walidacji, w celu zmierzenia jak dobrze sieć działa na zestawie testowym. Ponieważ nie aktualizujemy parametrów sici w trakcie walidacji, możemy przyspieszyć wykonanie kodu, wyłączając gradienty za pomocą `torch.no_grad()`:\n",
    "\n",
    "```python\n",
    "# wyłącz gradienty\n",
    "with torch.no_grad():\n",
    "    # kod walidacyjny\n",
    "    for images, labels in testloader:\n",
    "        ...\n",
    "```\n",
    "\n",
    ">**Ćwiczenie:** Zaimplementuj poniższą pętlę walidacji i wydrukuj całkowitą dokładność po pętli. Możesz w dużej mierze skopiować i wkleić powyższy kod, ale sugeruję wpisanie go, ponieważ napisanie go samodzielnie jest niezbędne do budowania umiejętności. Ogólnie rzecz biorąc, zawsze dowiesz się więcej, wpisując kod samodzielnie zamiast jego kopiowania i wklejania. Powinno uzyskać się dokładność powyżej 80%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-01T22:10:26.276573991Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mnn\u001B[49m\u001B[38;5;241m.\u001B[39mSequential(nn\u001B[38;5;241m.\u001B[39mLinear(\u001B[38;5;241m784\u001B[39m, \u001B[38;5;241m128\u001B[39m),\n\u001B[1;32m      2\u001B[0m                       nn\u001B[38;5;241m.\u001B[39mReLU(),\n\u001B[1;32m      3\u001B[0m                       nn\u001B[38;5;241m.\u001B[39mLinear(\u001B[38;5;241m128\u001B[39m, \u001B[38;5;241m128\u001B[39m),\n\u001B[1;32m      4\u001B[0m                       nn\u001B[38;5;241m.\u001B[39mReLU(),\n\u001B[1;32m      5\u001B[0m                       nn\u001B[38;5;241m.\u001B[39mLinear(\u001B[38;5;241m128\u001B[39m, \u001B[38;5;241m10\u001B[39m),\n\u001B[1;32m      6\u001B[0m                       nn\u001B[38;5;241m.\u001B[39mLogSoftmax(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m      8\u001B[0m criterion \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mNLLLoss()\n\u001B[1;32m      9\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.003\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 30\n",
    "steps = 0\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        log_ps = model(images)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            cum_accuracy = 0\n",
    "            val_loss = 0\n",
    "            for images, labels in testloader:\n",
    "                images = images.view(images.shape[0], -1)\n",
    "\n",
    "                log_ps = model(images)\n",
    "                loss = criterion(log_ps, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "\n",
    "                equals = top_class.squeeze() == labels\n",
    "                cum_accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "            accuracy = (cum_accuracy.item() / len(testloader)) * 100\n",
    "            print(f'Accuracy: {accuracy:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przeuczenie/Overfitting\n",
    "\n",
    "Jeśli przyjrzymy się stratom związanym z trenowaniem i walidacją podczas trenowania sieci, możemy zauważyć zjawisko zwane przeuczeniem/overfittingiem.\n",
    "\n",
    "<img src='assets/overfitting.png' width=450px>\n",
    "\n",
    "Sieć coraz lepiej uczy się zestawu treningowego, co skutkuje mniejszymi stratami treningowymi. Sieć zaczyna jednak mieć problemy z uogólnianiem wiedzy na dane spoza zbioru uczącego, co prowadzi do wzrostu straty na zbiorze walidacyjnym. Ostatecznym celem każdego modelu głębokiego uczenia jest przewidywanie nowych danych, dlatego powinniśmy dążyć do uzyskania jak najmniejszej możliwej straty dla walidacji. Jedną z opcji jest użycie wersji modelu o najmniejszym błędzie walidacji, w naszym modelu około 8-10 epok treningowych. Ta strategia nazywa się *wczesnym zatrzymaniem* *(ang. early-stopping)*. W praktyce często zapisuje się model podczas uczenia, a później wybiera się model o najmniejszym błędzie walidacji.\n",
    "\n",
    "Najpopularniejszą metodą redukcji overfittingu (poza wczesnym zatrzymaniem) jest *dropout*, gdzie losowo pomijamy neurony. Zmusza to sieć do dzielenia się informacjami między wagami, zwiększając jej zdolność do uogólniania na nowe dane. Dodawanie dropout w PyTorch jest proste dzięki modułowi [`nn.Dropout`](https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout).\n",
    "\n",
    "```python\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "        # Moduł dropout z prawdopodobieństwem pominięcią równym 0.2 \n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # upewnienie się, że tensor wejściowy jest płaski (wektor danych)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        # Tym razem z dropoutem\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        \n",
    "        # w warstwie wyjściowej nie stosuje się dropoutu\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        \n",
    "        return x\n",
    "```\n",
    "\n",
    "Podczas treningu chcemy wykorzystać dropout, aby zapobiec overfittingowi, ale podczas wnioskowania chcemy wykorzystać całą sieć. Dlatego musimy wyłączyć dropout podczas walidacji, testowania i za każdym razem, gdy używamy sieci do prognozowania. Aby to zrobić, użyj `model.eval()`. Ustawia to model w tryb oceny, w którym prawdopodobieństwo dropoutu wynosi 0. Możesz ponownie włączyć dropout, ustawiając model w trybie trenowania za pomocą `model.train()`. Ogólnie rzecz biorąc, wzorzec pętli walidacji w którym wyłączasz gradienty będzie wyglądał tak: ustawiasz model w tryb oceny, obliczasz stratę i metrykę walidacji, a następnie ustawiasz model z powrotem w tryb trenowania. \n",
    "\n",
    "```python\n",
    "# turn off gradients\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # validation pass here\n",
    "    for images, labels in testloader:\n",
    "        ...\n",
    "\n",
    "# set model back to train mode\n",
    "model.train()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ćwiczenie:** Dodaj dropout do swojego modelu i ponownie wytrenuj go w Fashion-MNIST. Sprawdź, czy możesz uzyskać mniejszą stratę walidacji lub wyższą dokładność. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-01T22:10:26.290376428Z"
    }
   },
   "outputs": [],
   "source": [
    "## TODO: Zdefiniuj swój model z dodanym przerywaniem\n",
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.3),  # Dropout\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.3),  # Dropout\n",
    "    nn.Linear(128, 10),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-01T22:10:26.290478548Z"
    }
   },
   "outputs": [],
   "source": [
    "## TODO: Trenuj swój model z dropoutem i monitoruj postępy w treningu wraz ze  stratą i dokładnością walidacji \n",
    "for e in range(epochs):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        log_ps = model(images)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    else:\n",
    "        train_loss = (running_loss / len(trainloader))\n",
    "        with torch.no_grad():\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            cum_accuracy = 0\n",
    "            val_loss = 0\n",
    "            for images, labels in testloader:\n",
    "                images = images.view(images.shape[0], -1)\n",
    "\n",
    "                log_ps = model(images)\n",
    "                loss = criterion(log_ps, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "\n",
    "                equals = top_class.squeeze() == labels\n",
    "                cum_accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "            test_loss = (val_loss / len(testloader))\n",
    "            accuracy = (cum_accuracy.item() / len(testloader)) * 100\n",
    "            print(f'Accuracy: {accuracy:.3f}%')\n",
    "\n",
    "            print(f\"Train loss: {train_loss:10.3f} | Test loss: {test_loss:10.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wnioskowanie\n",
    "\n",
    "Teraz, gdy model jest wytrenowany, możemy go użyć do wnioskowania. Robiliśmy to już wcześniej, ale teraz musimy pamiętać, aby ustawić model w trybie wnioskowania za pomocą `model.eval()`. Warto również wyłączyć autograd z kontekstem `torch.no_grad()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-01T22:10:26.290544513Z"
    }
   },
   "outputs": [],
   "source": [
    "# Zaimportuj moduł pomocniczy\n",
    "import helper\n",
    "\n",
    "# Przetestuj swoją sieć! \n",
    "\n",
    "model.eval()\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "img = images[0]\n",
    "# Przekształcenie obrazu 2D do wektora 1D\n",
    "img = img.view(1, 784)\n",
    "\n",
    "# Wyznaczenie prawdopodobieństw przynależności do klasy (softmax) dla img\n",
    "with torch.no_grad():\n",
    "    output = model.forward(img)\n",
    "\n",
    "ps = torch.exp(output)\n",
    "\n",
    "# Wyświetl obraz i prawdopodobieństwa \n",
    "helper.view_classify(img.view(1, 28, 28), ps, version='Fashion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zapisywanie i ładowanie modeli\n",
    "\n",
    "Teraz zajmiemy się tym jak zapisywać i ładować modele za pomocą PyTorch. Jest to ważne, ponieważ często chcemy załadować wcześniej wytrenowane modele, aby użyć ich do prognozowania lub kontynuować trenowanie na nowych danych. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-01T22:10:26.290610143Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import helper\n",
    "import fc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-01T22:10:26.290653542Z"
    }
   },
   "outputs": [],
   "source": [
    "# Zdefiniowanie przekształceń w celu normalizacji danych\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "# Pobranie i wcztanie zbioru treningowego\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Pobranie i wcztanie zbioru testowego\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podgląd wczytanego obrazka. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-01T22:10:26.296562526Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m image, label \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(\u001B[43mtrainloader\u001B[49m))\n\u001B[1;32m      2\u001B[0m helper\u001B[38;5;241m.\u001B[39mimshow(image[\u001B[38;5;241m0\u001B[39m, :]);\n",
      "\u001B[0;31mNameError\u001B[0m: name 'trainloader' is not defined"
     ]
    }
   ],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "helper.imshow(image[0, :]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trenowanie sieci\n",
    "\n",
    "Aby to było bardziej zwięzłe poprawna architektura modelu i kod uczący został przeniesiony do pliku o nazwie `fc_model`. Importując go, możemy łatwo stworzyć w pełni połączoną sieć za pomocą `fc_model.Network` i trenować sieć za pomocą `fc_model.train`. Możemy użyć tego modelu (po jego nauczeniu), aby zademonstrować, jak możemy zapisywać i ładować modele. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-01T22:10:26.301021274Z"
    }
   },
   "outputs": [],
   "source": [
    "# Utwórz sieć, zdefiniuj kryterium i optymalizator \n",
    "\n",
    "model = fc_model.Network(784, 10, [512, 256, 128])\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-01T22:10:26.301134435Z"
    }
   },
   "outputs": [],
   "source": [
    "fc_model.train(model, trainloader, testloader, criterion, optimizer, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zapisywanie i ładowanie sieci\n",
    "\n",
    "Jak można sobie wyobrazić, niepraktyczne jest trenowanie sieci za każdym razem, gdy musimy z niej korzystać. Zamiast tego możemy zapisać wytrenowane modele, a następnie załadować je później, aby trenować je dalej lub użyć ich do prognozowania.\n",
    "\n",
    "Parametry sieci PyTorch są przechowywane w modelu `state_dict`. Widzimy, że słownik stanu zawiera macierze wag i odchyleń/biasów dla każdej z naszych warstw. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-01T22:10:26.301183321Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Nasz model: \\n\\n\", model, '\\n')\n",
    "print(\"Klucze wektora stanu: \\n\\n\", model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najprostszą rzeczą do zrobienia jest po prostu zapisanie słownika stanu za pomocą `torch.save`. Na przykład możemy zapisać go do pliku `'checkpoint.pth'`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-01T22:10:26.305420713Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241m.\u001B[39msave(model\u001B[38;5;241m.\u001B[39mstate_dict(), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcheckpoint.pth\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Następnie możemy załadować słownik stanu za pomocą `torch.load`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-01T22:10:26.309686592Z"
    }
   },
   "outputs": [],
   "source": [
    "state_dict = torch.load('checkpoint.pth')\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby załadować słownik stanu do sieci, wywołujemy `model.load_state_dict(state_dict)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-01T22:10:26.309803095Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wydaje się całkiem proste, ale jak zwykle jest trochę bardziej skomplikowane. Ładowanie słownika stanu działa tylko wtedy, gdy architektura modelu jest dokładnie taka sama jak architektura punktu kontrolnego. Jeśli zbudujemy model o innej architekturze, to operacja ta się nie powiedzie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-01T22:10:26.316701195Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fc_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Spróbuj to\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mfc_model\u001B[49m\u001B[38;5;241m.\u001B[39mNetwork(\u001B[38;5;241m784\u001B[39m, \u001B[38;5;241m10\u001B[39m, [\u001B[38;5;241m400\u001B[39m, \u001B[38;5;241m200\u001B[39m, \u001B[38;5;241m100\u001B[39m])\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Spowoduje to błąd, ponieważ rozmiary tensorów są nieprawidłowe! \u001B[39;00m\n\u001B[1;32m      4\u001B[0m model\u001B[38;5;241m.\u001B[39mload_state_dict(state_dict)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'fc_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Spróbuj to\n",
    "model = fc_model.Network(784, 10, [400, 200, 100])\n",
    "# Spowoduje to błąd, ponieważ rozmiary tensorów są nieprawidłowe! \n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oznacza to, że musimy zbudować model dokładnie taki, jaki był podczas trenowania. Informacje o architekturze modelu muszą być zapisane w punkcie kontrolnym wraz ze stanem. Aby to zrobić, budujemy słownik zawierający wszystkie informacje potrzebne do całkowitego przebudowania modelu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-01T22:10:26.360323651Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = {'input_size': 784,\n",
    "              'output_size': 10,\n",
    "              'hidden_layers': [each.out_features for each in model.hidden_layers],\n",
    "              'state_dict': model.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz punkt kontrolny ma wszystkie niezbędne informacje do odbudowania wytrenowanego modelu. Można łatwo ustawić tę funkcję. Podobnie możemy napisać funkcję do ładowania punktów kontrolnych. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-01T22:10:26.360409770Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = fc_model.Network(checkpoint['input_size'],\n",
    "                             checkpoint['output_size'],\n",
    "                             checkpoint['hidden_layers'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-01T22:10:26.360444988Z"
    }
   },
   "outputs": [],
   "source": [
    "model = load_checkpoint('checkpoint.pth')\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
