{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wprowadzenie do głębokiego uczenia w PyTorch\n",
    "\n",
    "W tym notatniku zapoznasz się z [PyTorch](http://pytorch.org/), pakietem do tworzenia i trenowania sieci neuronowych. PyTorch na wiele sposobów zachowuje się jak tablice z Numpy, które nazywane są tutaj tensorami. PyTorch wykorzystuje  tensory i ułatwia przenoszenie ich na procesory graficzne w celu szybszego przetwarzania potrzebnego podczas uczenia sieci neuronowych. Zawiera również moduł, który automatycznie oblicza gradienty (dla propagacji wstecznej!) oraz inny moduł przeznaczony specjalnie do budowania sieci neuronowych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieć Neuronowa\n",
    "\n",
    "Głębokie uczenie opiera się na sztucznych sieciach neuronowych, które istnieją w jakiejś formie od późnych lat pięćdziesiątych. Sieci są zbudowane z pojedynczych części aproksymujących neurony, zwykle nazywanych jednostkami lub po prostu „neuronami”. Każda jednostka ma pewną ilość ważonych wejść. Przeważone dane wejściowe są sumowane (przy pomocy kombinacji liniowej), a następnie przepuszczane przez funkcję aktywacji, w celu otrzymania danych wyjściowych. \n",
    "\n",
    "<img src=\"assets/simple_neuron.png\" width=400px>\n",
    "\n",
    "Formalnie wygląda to następująco: \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "y &= f(w_1 x_1 + w_2 x_2 + b) \\\\\n",
    "y &= f\\left(\\sum_i w_i x_i +b \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "W przypadku wektorów jest to iloczyn skalarny/wewnętrzny dwóch wektorów (ang. dot/inner product of two vectors):\n",
    "\n",
    "$$\n",
    "h = \\begin{bmatrix}\n",
    "x_1 \\, x_2 \\cdots  x_n\n",
    "\\end{bmatrix}\n",
    "\\cdot \n",
    "\\begin{bmatrix}\n",
    "           w_1 \\\\\n",
    "           w_2 \\\\\n",
    "           \\vdots \\\\\n",
    "           w_n\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensory\n",
    "\n",
    "Okazuje się, że obliczenia w sieciach neuronowych są tylko zbiorem operacji algebry liniowej na *tensorach*, uogólnieniu macierzy. Wektor jest tensorem jednowymiarowym, macierz jest tensorem dwuwymiarowym, tablica z trzema indeksami jest tensorem trójwymiarowym (na przykład kolorowe obrazy RGB). Podstawową strukturą danych dla sieci neuronowych są tensory, a PyTorch (podobnie jak prawie każdy inny framework do głębokiego uczenia się) jest zbudowany wokół tensorów. \n",
    "\n",
    "<img src=\"assets/tensor_examples.svg\" width=600px>\n",
    "\n",
    "Po omówieniu podstaw nadszedł czas, aby zbadać, w jaki sposób możemy wykorzystać PyTorch do zbudowania prostej sieci neuronowej. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import PyTorch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    \"\"\" Sigmoid activation function \n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        x: torch.Tensor\n",
    "    \"\"\"\n",
    "    return 1/(1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generowanie danych\n",
    "torch.manual_seed(7) # Ustawienie ziarna\n",
    "\n",
    "# Losujemy 5 zmiennych (wektor danych wejściowych)\n",
    "features = torch.randn((1, 5))\n",
    "# Losujemy wagi dla naszych danych wejściowych\n",
    "weights = torch.randn_like(features)\n",
    "# i bias\n",
    "bias = torch.randn((1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powyżej wygenerowaliśy dane, które możemy wykorzystać do uzyskania wyniku naszej prostej sieci. Na razie to wszystko jest po prostu losowe, w przyszłości zaczniemy używać normalnych danych. Analizując każdą powyższą linię:\n",
    "\n",
    "`features = torch.randn((1, 5))` tworzy tensor o wymiarach `(1, 5)`, jednym wierszu i pięciu kolumnach, który zawiera losowe wartości z rozkładu normalnego (średnia 0 i odchylenie standardowe 1). \n",
    "\n",
    "`weights = torch.randn_like(features)` tworzy losowy tensor o wymiarach tensora `features`, również używając rozkładu normalnego.\n",
    "\n",
    "Ostatecznie, `bias = torch.randn((1, 1))` losuje pojedynczą wartość z rozkładu normalnego. \n",
    "\n",
    "Tensory PyTorch można dodawać, mnożyć, odejmować itp., podobnie jak tablice Numpy. Ogólnie rzecz biorąc, będziemy używać tensorów PyTorch w taki sam sposób, w jaki używa się tablic Numpy. Mają one jednak kilka fajnych korzyści, takich jak przyspieszenie GPU, do którego przejdziemy później. Na razie użyj wygenerowanych danych, aby obliczyć dane wyjściowe tej prostej sieci jednowarstwowej.\n",
    "> **Ćwiczenie**: oblicz wyjście sieci za pomocą danych wejściowych „features”, wag „weights” i wyrazu wolnego „bias”. Podobnie jak Numpy, PyTorch ma funkcję [`torch.sum()`](https://pytorch.org/docs/stable/torch.html#torch.sum), a także metodę `.sum()` na tensorach, do liczenia sum. Użyj funkcji „activation” zdefiniowanej powyżej jako funkcji aktywacji. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Oblicz wynik tej sieci za pomocą wag i tensorów odchylenia \n",
    "\n",
    "w = activation(weights * features + bias)\n",
    "\n",
    "r = torch.sum(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x5 and 1x5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x5 and 1x5)"
     ]
    }
   ],
   "source": [
    "torch.mm(features, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możesz wykonać mnożenie i sumowanie w tej samej operacji, używając mnożenia macierzy. Ogólnie rzecz biorąc warto używać mnożenia macierzy, ponieważ są one bardziej wydajne i przyspieszane przy użyciu nowoczesnych bibliotek i obliczeń o wysokiej wydajności na procesorach graficznych.\n",
    "\n",
    "Tutaj chcemy wykonać macierzowe pomnożenie cech i wag. W tym celu możemy użyć [`torch.mm()`](https://pytorch.org/docs/stable/torch.html#torch.mm) lub [`torch.matmul()`](https:// pytorch.org/docs/stable/torch.html#torch.matmul), który jest nieco bardziej skomplikowany i obsługuje rozgłoszenia (ang. broadcasting). Jeśli spróbujesz użyć tej funkcji z `features` i `weights` w takiej formie w jakiej są otrzymasz błąd.\n",
    "\n",
    "Powstały błąd jest wynikiem tego, że nasze tensory nie mają odpowiednich wymiarów do mnożenia macierzy. Pamiętaj, że w przypadku mnożenia macierzy liczba kolumn w pierwszym tensorze musi być równa liczbie wierszy w drugim.  Tensory `features` oraz `weights` mają ten sam wymiar, `(1, 5)`. Oznacza to, że musimy zmienić kształt `weights` aby mnożenie macierzy zadziałało. \n",
    "\n",
    "**Uwaga:** aby zobaczyć kształt tensora o nazwie `tensor`, użyj `tensor.shape`. Jeśli budujesz sieci neuronowe, będziesz często używać tej metody. \n",
    "\n",
    "Mamy kilka możliwości: [`weights.reshape()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.reshape), [`weights.resize_()`]( https://pytorch.org/docs/stable/tensors.html#torch.Tensor.resize_) i [`weights.view()`](https://pytorch.org/docs/stable/tensors.html# torch.tensor.view).\n",
    "\n",
    "* `weights.reshape(a, b)` zwróci nowy tensor z tymi samymi danymi co `weights` o rozmiarze `(a, b)` czasami, a czasami klon, ponieważ kopiuje dane do innej części pamięć.\n",
    "* `weights.resize_(a, b)` zwraca ten sam tensor o innym kształcie. Jeśli jednak nowy kształt da w wyniku mniej elementów niż oryginalny tensor, niektóre elementy zostaną usunięte z tensora (ale nie z pamięci). Jeśli nowy kształt da w wyniku więcej elementów niż oryginalny tensor, nowe elementy nie zostaną zainicjowane w pamięci. W tym miejscu można zauważyć, że podkreślenie na końcu metody oznacza, że ​​metoda ta jest wykonywana **w miejscu**. Oto świetny wątek na forum, aby [przeczytać więcej o operacjach w miejscu](https://discuss.pytorch.org/t/what-is-in-place-operation/16244) w PyTorch.\n",
    "* `weights.view(a, b)` zwróci nowy tensor z takimi samymi danymi jak `weights` o rozmiarze `(a, b)`.\n",
    "\n",
    "Zwykle używa się `.view()`, ale każda z trzech metod będzie działać. Tak więc, teraz możemy zmienić kształt `weights`, aby mieć pięć wierszy i jedną kolumnę za pomocą komendy `weights.view(5, 1)`.\n",
    "\n",
    "> **Ćwiczenie**: Oblicz wynik naszej małej sieci za pomocą mnożenia macierzy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9796]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Wyliczenie wyjścia sieci przy pomocy mnożenia macierzy\n",
    "y = torch.mm(features, weights.view(5,1))\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Układanie neuronów w stos\n",
    "\n",
    "Łącząc neuronwy w stos możemy zobaczyć prawdziwą moc algorytmu pojawia. W tym celu lączymy pojedyncze jednostki w warstwy i stosy warstw w sieć neuronów. Wyjście jednej warstwy neuronów staje się wejściem dla następnej warstwy. Przy wielu jednostkach wejściowych i jednostkach wyjściowych musimy teraz wyrazić wagi jako macierz. \n",
    "\n",
    "<img src='assets/multilayer_diagram_weights.png' width=450px>\n",
    "\n",
    "Pierwsza warstwa pokazana na dole to dane wejściowe, co zrozumiałe nazywa się **warstwą wejściową**. Warstwa środkowa to **warstwa ukryta**, a warstwa końcowa (po prawej) to **warstwa wyjściowa**. Możemy ponownie wyrazić tę sieć matematycznie za pomocą macierzy i użyć mnożenia macierzy, aby uzyskać kombinacje liniowe dla każdej jednostki w jednej operacji. Na przykład można obliczyć ukrytą warstwę ($h_1$ i $h_2$) \n",
    "\n",
    "$$\n",
    "\\vec{h} = [h_1 \\, h_2] = \n",
    "\\begin{bmatrix}\n",
    "x_1 \\, x_2 \\cdots \\, x_n\n",
    "\\end{bmatrix}\n",
    "\\cdot \n",
    "\\begin{bmatrix}\n",
    "           w_{11} & w_{12} \\\\\n",
    "           w_{21} &w_{22} \\\\\n",
    "           \\vdots &\\vdots \\\\\n",
    "           w_{n1} &w_{n2}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Dane wyjściowe dla tej małej sieci można znaleźć, traktując ukrytą warstwę jako dane wejściowe dla jednostki wyjściowej. Dane wyjściowe sieci są wyrażane w prosty sposób \n",
    "\n",
    "$$\n",
    "y =  f_2 \\! \\left(\\, f_1 \\! \\left(\\vec{x} \\, \\mathbf{W_1}\\right) \\mathbf{W_2} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generowanie danych\n",
    "torch.manual_seed(7) # Ustaw ziarno\n",
    "\n",
    "# Wylosowanie wektora 3 cech\n",
    "features = torch.randn((1, 3))\n",
    "\n",
    "# Określenie rozmiaru każdej warstwy w naszej sieci \n",
    "n_input = features.shape[1]     # Ilość neuronów wejściowych, musi być zgodna z wielkością wektora wejściowego\n",
    "n_hidden = 2                    # Ilość neuronów ukrytych\n",
    "n_output = 1                    # Ilośc neuronów wyjściowych\n",
    "\n",
    "# Wagi dla sygnałów przechodzących z wejścia do ukrytej warstwy \n",
    "W1 = torch.randn(n_input, n_hidden)\n",
    "# Wagi dla sygnałów przechodzących z warstwy ukrytej do warstwy wyjściowej \n",
    "W2 = torch.randn(n_hidden, n_output)\n",
    "\n",
    "# i bias dla warstwy ukrytej i wyjściowej \n",
    "B1 = torch.randn((1, n_hidden))\n",
    "B2 = torch.randn((1, n_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ćwiczenie:** Oblicz wynik dla tej sieci wielowarstwowej wykorzystując wagi  `W1` & `W2` i biasów, `B1` & `B2`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3171]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Miejsce na rozwiązanie\n",
    "Whx = activation(torch.mm(features, W1) + B1)\n",
    "Why = activation(torch.mm(Whx, W2) + B2)\n",
    "\n",
    "Why"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poprawny wynik wynosi  `tensor([[ 0.3171]])`.\n",
    "\n",
    "Liczba jednostek ukrytych to parametr sieci, często nazywany **hiperparametrem** w celu odróżnienia go od parametrów wag i odchyleń. Jak zobaczysz później, gdy będziemy omawiać uczenie sieci neuronowej, im więcej ukrytych jednostek ma sieć i im więcej warstw, tym lepiej jest w stanie uczyć się na podstawie danych i dokonywać dokładnych prognoz. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy do Torch i z powrotem\n",
    "\n",
    "PyTorch ma świetną funkcję do konwersji między tablicami Numpy i tensorami Torch. Aby utworzyć tensor z tablicy Numpy, użyj `torch.from_numpy()`. Aby przekonwertować tensor na tablicę Numpy, użyj metody `.numpy()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94830006, 0.04281766, 0.39272678],\n",
       "       [0.73669471, 0.39496956, 0.21414976],\n",
       "       [0.31792966, 0.58949968, 0.86949089],\n",
       "       [0.28563749, 0.09882535, 0.29148487]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.random.rand(4,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9483, 0.0428, 0.3927],\n",
       "        [0.7367, 0.3950, 0.2141],\n",
       "        [0.3179, 0.5895, 0.8695],\n",
       "        [0.2856, 0.0988, 0.2915]], dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.from_numpy(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94830006, 0.04281766, 0.39272678],\n",
       "       [0.73669471, 0.39496956, 0.21414976],\n",
       "       [0.31792966, 0.58949968, 0.86949089],\n",
       "       [0.28563749, 0.09882535, 0.29148487]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pamięć jest dzielona między tablicę Numpy i tensor Torch, więc jeśli zmienisz wartości w miejscu jednego obiektu, drugi również się zmieni. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8966, 0.0856, 0.7855],\n",
       "        [1.4734, 0.7899, 0.4283],\n",
       "        [0.6359, 1.1790, 1.7390],\n",
       "        [0.5713, 0.1977, 0.5830]], dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pomnóż tensor PyTorch przez 2\n",
    "b.mul_(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.89660013, 0.08563532, 0.78545356],\n",
       "       [1.47338943, 0.78993911, 0.42829952],\n",
       "       [0.63585932, 1.17899936, 1.73898177],\n",
       "       [0.57127498, 0.1976507 , 0.58296974]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tablica Numpy pasuje do nowych wartości Tensora \n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sieci neuronowe z PyTorch \n",
    "\n",
    "Sieci uczenia głębokiego są zwykle ogromne i składają się z dziesiątek lub setek warstw, stąd termin „głęboki”. Możesz zbudować jedną z tych głębokich sieci, używając tylko macierzy wag, tak jak to zrobiliśmy poprzednio, ale generalnie jest to bardzo kłopotliwe i trudne do zaimplementowania. PyTorch posiada moduł `nn`, który zapewnia dobry sposób na wydajne budowanie dużych sieci neuronowych. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import wymaganych pakietów\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import helper\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz zbudujemy większą sieć, która może rozwiązać (wcześniej) trudny problem, identyfikując tekst na obrazie. Tutaj użyjemy zestawu danych MNIST, który składa się z odręcznych cyfr w skali szarości. Każdy obraz ma wymiary 28x28 pikseli. Poniżej przykładowa próbka danych\n",
    "\n",
    "<img src='assets/mnist.png'>\n",
    "\n",
    "Naszym celem jest zbudowanie sieci neuronowej, która może wziąć jeden z tych obrazów i przewidzieć cyfrę na nim zapisaną.\n",
    "\n",
    "Najpierw musimy pobrać nasz zestaw danych. Zapewnia to pakiet `torchvision`. Poniższy kod pobierze zestaw danych MNIST, a następnie utworzy dla nas zestawy danych treningowych i testowych. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uruchom blok\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Zdefiniuj transformację, aby znormalizować dane \n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# Pobierz i załaduj dane treningowe \n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mamy dane treningowe załadowane do `trainloader` i robimy z niego iterator za pomocą `iter(trainloader)`. Później użyjemy tego, aby przejść przez zbiór danych do treningu, na przykład\n",
    "\n",
    "```python\n",
    "for image, label in trainloader:\n",
    "    ## rób rzeczy z obrazami i etykietami\n",
    "```\n",
    "\n",
    "Zauważysz, że stworzyliśmy `trainloader` z wielkością partii 64 i `shuffle=True`. Rozmiar partii/wsadu (batcha) to liczba obrazów, które otrzymujemy w jednej iteracji z modułu ładującego dane i przechodzimy przez naszą sieć. A `shuffle=True` mówi, aby tasował zestaw danych za każdym razem, gdy zaczynamy ponownie przechodzić przez program ładujący dane. Ale tutaj po prostu chwytam pierwszą partię, abyśmy mogli sprawdzić dane. Jak widać poniżej, `images` to tensor o rozmiarze `(64, 1, 28, 28)`. Tak więc 64 obrazy na partię, 1 kanał koloru i rozmiar obrazu 28x28. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tak wygląda jeden z obrazów. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 413,
       "width": 417
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najpierw spróbujmy zbudować prostą sieć dla tego zbioru danych, używając macierzy wag i mnożenia macierzy. Następnie zobaczymy, jak to zrobić za pomocą modułu `nn` PyTorch, który zapewnia znacznie wygodniejszą i wydajniejszą metodę definiowania architektur sieciowych.\n",
    "\n",
    "Sieci, które były prezentowane do tej pory, nazywają się *w pełni połączonymi* lub *gęstymi* sieciami. Każda jednostka w jednej warstwie jest połączona z każdą jednostką w następnej warstwie. W całkowicie połączonych sieciach dane wejściowe do każdej warstwy muszą być jednowymiarowym wektorem (który można ułożyć w tensor 2D jako partię wielu przykładów). Jednak nasze obrazy to 28x28 tensory 2D, więc musimy je przekonwertować na wektory 1D. Myśląc o rozmiarach, musimy przekonwertować partię obrazków o kształcie `(64, 1, 28, 28)` na kształt `(64, 784)`, 784 to 28 razy 28. Zwykle nazywa się to *flattening*, spłaszczyliśmy obrazy 2D do wektorów 1D.\n",
    "\n",
    "Wcześniej budowaliśmy sieć z jedną jednostką wyjściową. Tutaj potrzebujemy 10 jednostek wyjściowych, po jednej dla każdej cyfry. Chcemy, aby nasza sieć przewidziała cyfrę pokazaną na obrazku, więc obliczymy prawdopodobieństwa, że ​​obraz ma jedną cyfrę lub klasę. To kończy się dyskretnym rozkładem prawdopodobieństwa na klasy (cyfry), który mówi nam o najbardziej prawdopodobnej klasie obrazu. Oznacza to, że potrzebujemy 10 jednostek wyjściowych dla 10 klas (cyfr). Zobaczymy, jak przekonwertować wynik sieciowy na rozkład prawdopodobieństwa.\n",
    "\n",
    "> **Ćwiczenie:** spłaszcz partię obrazów „images”. Następnie zbuduj wielowarstwową sieć z 784 jednostkami wejściowymi, 256 jednostkami ukrytymi i 10 jednostkami wyjściowymi, używając losowych tensorów dla wag i obciążeń. Na razie użyj sigmoidalnej funkcji aktywacji dla ukrytej warstwy. Pozostaw warstwę wyjściową bez aktywacji, dodamy taką, która da nam rozkład prawdopodobieństwa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "## Twoje rozwiązanie\n",
    "def activation(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "flatten = nn.Flatten()\n",
    "features = flatten(images)\n",
    "\n",
    "n_input = features.shape[1]     # Ilość neuronów wejściowych, musi być zgodna z wielkością wektora wejściowego\n",
    "n_hidden = 256                  # Ilość neuronów ukrytych\n",
    "n_output = 10                   # Ilośc neuronów wyjściowych\n",
    "\n",
    "W1 = torch.randn(n_input, n_hidden)\n",
    "W2 = torch.randn(n_hidden, n_output)\n",
    "\n",
    "B1 = torch.randn((1, n_hidden))\n",
    "B2 = torch.randn((1, n_output))\n",
    "    \n",
    "Whx = activation(torch.mm(features, W1) + B1)\n",
    "Why = activation(torch.mm(Whx, W2) + B2)\n",
    "\n",
    "Why.shape\n",
    "# wyjście Twojej sieci powinno mieć kształt  (64,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz mamy sieć z 10 wyjściami. Chcemy przekazać obraz do naszej sieci i uzyskać rozkład prawdopodobieństwa w klasach, który mówi nam o prawdopodobieństwie z jakim przypisalibyśmy obraz do danej klasy. Wyglądać to będzie tak:\n",
    "<img src='assets/image_distribution.png' width=500px>\n",
    "\n",
    "Widzimy, że prawdopodobieństwo dla każdej klasy jest mniej więcej takie samo. Reprezentuje to sieć niewytrenowaną, która nie widziała jeszcze żadnych danych, więc po prostu zwraca jednolitą dystrybucję z równymi prawdopodobieństwami dla każdej klasy.\n",
    "\n",
    "Aby obliczyć ten rozkład prawdopodobieństwa, często używamy [funkcji **softmax**](https://en.wikipedia.org/wiki/Softmax_function). Opisana jest ona następującym równaniem:\n",
    "\n",
    "$$\n",
    "\\Large \\sigma(x_i) = \\cfrac{e^{x_i}}{\\sum_k^K{e^{x_k}}}\n",
    "$$\n",
    "\n",
    "To, co robi, to skaluje każde wejście $x_i$ między 0 a 1 i normalizuje wartości, aby uzyskać właściwy rozkład prawdopodobieństwa, w którym prawdopodobieństwa sumują się do jednego.\n",
    "\n",
    "> **Ćwiczenie:** Zaimplementuj funkcję `softmax`, która wykonuje obliczenia softmax i zwraca rozkłady prawdopodobieństwa dla każdego przykładu w partii. Pamiętaj, że podczas wykonywania tej czynności musisz zwracać uwagę na kształty. Jeśli masz tensor `a` o kształcie `(64, 10)` i tensor `b` o kształcie `(64,)`, wykonanie `a/b` da ci błąd, ponieważ PyTorch spróbuje wykonać podział na kolumny (tzw. rozgłaszanie), ale otrzymasz niezgodność rozmiaru. Sposób myślenia o tym jest taki, że dla każdego z 64 przykładów chcesz podzielić tylko przez jedną wartość, sumę w mianowniku. Musisz więc `b` mieć w rozmiarze `(64, 1)`. W ten sposób PyTorch podzieli 10 wartości w każdym wierszu `a` przez jedną wartość w każdym wierszu `b`. Zwróć również uwagę na to, jaką bierzesz sumę. Musisz zdefiniować wymiar `dim` po którym sumujesz `torch.sum`. Ustawienie `dim=0` powoduje wyznaczenie sumy w wierszy, a `dim=1` kolumn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12.4543],\n",
       "        [14.0399],\n",
       "        [15.6889],\n",
       "        [17.0876],\n",
       "        [15.7748],\n",
       "        [15.0760],\n",
       "        [15.5452],\n",
       "        [18.1084],\n",
       "        [14.5636],\n",
       "        [12.1056],\n",
       "        [13.4510],\n",
       "        [12.9508],\n",
       "        [18.2560],\n",
       "        [15.3718],\n",
       "        [16.9756],\n",
       "        [13.5189],\n",
       "        [13.9343],\n",
       "        [19.1256],\n",
       "        [15.1089],\n",
       "        [19.3441],\n",
       "        [17.5144],\n",
       "        [15.5068],\n",
       "        [15.7190],\n",
       "        [15.7923],\n",
       "        [14.6779],\n",
       "        [17.3039],\n",
       "        [16.8244],\n",
       "        [15.6675],\n",
       "        [13.3755],\n",
       "        [16.5081],\n",
       "        [15.1201],\n",
       "        [16.2007],\n",
       "        [18.4347],\n",
       "        [13.0772],\n",
       "        [13.3234],\n",
       "        [16.6217],\n",
       "        [20.0367],\n",
       "        [16.1778],\n",
       "        [15.7310],\n",
       "        [15.6055],\n",
       "        [17.0848],\n",
       "        [16.5489],\n",
       "        [14.1911],\n",
       "        [16.5382],\n",
       "        [15.0867],\n",
       "        [19.4835],\n",
       "        [13.9839],\n",
       "        [19.2850],\n",
       "        [16.1379],\n",
       "        [14.9589],\n",
       "        [17.6232],\n",
       "        [16.4617],\n",
       "        [15.5182],\n",
       "        [11.8178],\n",
       "        [17.1546],\n",
       "        [17.2751],\n",
       "        [19.5539],\n",
       "        [15.0171],\n",
       "        [13.5192],\n",
       "        [16.9420],\n",
       "        [13.9011],\n",
       "        [12.0290],\n",
       "        [14.7848],\n",
       "        [18.2771]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.exp(Why), dim=1).view(64,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    ## TODO: Zaimplementuj funkcję softmax\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(64,1)\n",
    "\n",
    "# W tym miejscu out to wyjście sieci z poprzedniego ćwiczenia o rozmiarze (64,10)\n",
    "probabilities = softmax(Why)\n",
    "\n",
    "# Sprawdźmy czy rozmiar jest właściwy. Powinien być (64, 10)\n",
    "print(probabilities.shape)\n",
    "# Czy prawdopodobieństwa sumują się do 1?\n",
    "print(torch.sum(probabilities[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0803, 0.0803, 0.1385, 0.0803, 0.2119, 0.0833, 0.0803, 0.0805, 0.0803,\n",
      "        0.0843])\n"
     ]
    }
   ],
   "source": [
    "print(probabilities[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Budowanie sieci za pomocą PyTorch\n",
    "\n",
    "PyTorch dostarcza moduł `nn`, który znacznie upraszcza budowanie sieci. Tutaj pokażemy, jak zbudować taką samą architekturę, jak powyżej, z 784 wejściami, 256 ukrytymi jednostkami, 10 jednostkami wyjściowymi i wyjściem softmax. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Dane wejściowe do transformacji liniowej warstwy ukrytej \n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # Warstwa wyjściowa, 10 neuronów - jeden na każdą cyfrę \n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "        # Zdefiniuj aktywację sigmoidalną i wyjście softmax \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Przekaż tensor wejściowy przez każdą z naszych operacji \n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utwórz sieć i spójrz na jej reprezentację tekstową \n",
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możesz zdefiniować sieć nieco bardziej zwięźle i przejrzyście za pomocą modułu `torch.nn.functional`. Jest to najczęstszy sposób, w jaki definiuje się sieci, ponieważ wiele operacji to proste funkcje oparte na podstawowych elementach. Normalnie importujemy ten moduł jako `F`, `import torch.nn.functional as F`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Dane wejściowe do transformacji liniowej warstwy ukrytej\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # Warstwa wyjściowa, 10 neuronów - jeden na każdą cyfrę\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Warstwa ukryta z sigmoidalną funkcją aktywacji\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        # Warstwa wyjściowa z funkcją aktywacji softmax\n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcje aktywacji\n",
    "\n",
    "Do tej pory przyglądaliśmy się tylko sigmoidalnej funkcji aktywacji, ale ogólnie każda funkcja może być używana jako funkcja aktywacji. Jedynym wymaganiem jest to, że aby sieć mogła aproksymować funkcję nieliniową, funkcje aktywacji muszą być nieliniowe. Oto kilka innych przykładów typowych funkcji aktywacji: Tanh (tangens hiperboliczny) i ReLU (rektyfikowana jednostka liniowa).\n",
    "\n",
    "<img src=\"assets/activation.png\" width=700px>\n",
    "\n",
    "W praktyce funkcja ReLU jest wykorzystywana prawie wyłącznie jako funkcja aktywacji dla warstw ukrytych. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twoja kolej na zbudowanie sieci\n",
    "\n",
    "<img src=\"assets/mlp_mnist.png\" width=600px>\n",
    "\n",
    "> **Ćwiczenie:** Utwórz sieć z 784 jednostkami wejściowymi, warstwą ukrytą z 128 jednostkami i aktywacją ReLU, następnie warstwę ukrytą z 64 jednostkami i aktywacją ReLU, a na koniec warstwę wyjściową z aktywacją softmax, jak pokazano powyżej. Możesz użyć aktywacji ReLU z modułem `nn.ReLU` lub funkcją `F.relu`.\n",
    "\n",
    "Dobrą praktyką jest nazywanie warstw według ich typu sieci, na przykład 'fc', aby reprezentować w pełni połączoną warstwę. Podczas kodowania rozwiązania użyj `fc1`, `fc2` i `fc3` jako nazw warstw. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Miejsce na rozwiązanie\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x), dim=1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicjowanie wag i odchyleń\n",
    "\n",
    "Wagi i tym podobne są automatycznie inicjowane, ale można dostosować sposób ich inicjowania. Wagi i obciążenia to tensory dołączone do zdefiniowanej warstwy, można je uzyskać na przykład za pomocą `model.fc1.weight`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0303,  0.0047, -0.0060,  ...,  0.0235,  0.0012, -0.0335],\n",
      "        [ 0.0141,  0.0220,  0.0141,  ..., -0.0081,  0.0335, -0.0211],\n",
      "        [-0.0301, -0.0065,  0.0150,  ...,  0.0091, -0.0224, -0.0060],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0191,  0.0257,  ..., -0.0219,  0.0255, -0.0272],\n",
      "        [ 0.0334, -0.0019, -0.0155,  ..., -0.0205,  0.0314, -0.0051],\n",
      "        [-0.0152,  0.0289,  0.0296,  ..., -0.0032,  0.0309,  0.0017]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0203, -0.0101,  0.0036, -0.0251, -0.0256, -0.0087,  0.0092, -0.0355,\n",
      "         0.0127, -0.0146, -0.0254, -0.0126, -0.0269,  0.0212,  0.0112, -0.0237,\n",
      "         0.0278,  0.0016, -0.0003,  0.0029, -0.0072,  0.0156,  0.0173, -0.0053,\n",
      "         0.0148,  0.0055,  0.0167, -0.0079,  0.0071,  0.0239,  0.0309,  0.0081,\n",
      "         0.0260,  0.0178, -0.0177,  0.0286, -0.0192,  0.0316, -0.0331, -0.0061,\n",
      "        -0.0203, -0.0219,  0.0069, -0.0191,  0.0133, -0.0211,  0.0017,  0.0135,\n",
      "        -0.0236, -0.0094,  0.0270,  0.0357, -0.0104,  0.0139,  0.0025, -0.0290,\n",
      "         0.0053, -0.0285,  0.0193, -0.0171,  0.0198,  0.0064,  0.0045,  0.0033,\n",
      "        -0.0205, -0.0122,  0.0348, -0.0299, -0.0246,  0.0097, -0.0101, -0.0285,\n",
      "         0.0185,  0.0236,  0.0244, -0.0269, -0.0338, -0.0353,  0.0282,  0.0088,\n",
      "        -0.0025, -0.0083, -0.0050,  0.0320, -0.0272, -0.0181,  0.0189,  0.0148,\n",
      "        -0.0171, -0.0174, -0.0209, -0.0208, -0.0314, -0.0042, -0.0348, -0.0181,\n",
      "         0.0190, -0.0095, -0.0222, -0.0178, -0.0203,  0.0185,  0.0187,  0.0090,\n",
      "        -0.0006,  0.0076,  0.0315,  0.0056, -0.0163, -0.0264,  0.0211,  0.0257,\n",
      "        -0.0102,  0.0162, -0.0246, -0.0264, -0.0353,  0.0094,  0.0132,  0.0222,\n",
      "         0.0061, -0.0267,  0.0225,  0.0054,  0.0100,  0.0295,  0.0133, -0.0244],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.fc1.weight)\n",
    "print(model.fc1.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W przypadku niestandardowej inicjalizacji chcemy zmodyfikować te tensory na miejscu. W rzeczywistości są to *Zmienne* autogradientu, więc musimy odzyskać rzeczywiste tensory za pomocą `model.fc1.weight.data`. Kiedy już mamy tensory, możemy wypełnić je zerami (dla błędów systematycznych) lub losowymi wartościami normalnymi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ustawiamy biasy na zero\n",
    "model.fc1.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0044,  0.0075, -0.0091,  ..., -0.0029, -0.0191, -0.0109],\n",
       "        [-0.0039,  0.0115,  0.0018,  ...,  0.0032, -0.0116,  0.0238],\n",
       "        [ 0.0001, -0.0048, -0.0022,  ..., -0.0073,  0.0073, -0.0150],\n",
       "        ...,\n",
       "        [ 0.0003, -0.0006,  0.0089,  ..., -0.0065,  0.0105, -0.0093],\n",
       "        [ 0.0069, -0.0074,  0.0049,  ..., -0.0027,  0.0132,  0.0289],\n",
       "        [ 0.0017,  0.0128, -0.0048,  ..., -0.0103, -0.0042, -0.0028]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Losujemy wagi z rozkładu normalnego dla odchylenia standardowego = 0.01\n",
    "model.fc1.weight.data.normal_(std=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagacja w przodu\n",
    "\n",
    "Teraz, gdy mamy sieć, zobaczmy, co się dzieje, gdy przechodzimy przez nią obraz podanym na wejście. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x900 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 327,
       "width": 589
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Zbież partię danych \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Zmień rozmiar obrazów na wektor 1D, nowy kształt to (rozmiar wsadu, kanały kolorów, piksele obrazu) \n",
    "images.resize_(64, 1, 784)\n",
    "# lub images.resize_(images.shape[0], 1, 784) aby automatycznie uzyskać rozmiar partii\n",
    "\n",
    "# Przekazywanie przez sieć \n",
    "img_idx = 0\n",
    "ps = model.forward(images[img_idx,:])\n",
    "\n",
    "img = images[img_idx]\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać powyżej, nasza sieć w zasadzie nie ma pojęcia, co to za cyfra. To dlatego, że jeszcze tego nie trenowaliśmy, wszystkie ciężary są losowe!\n",
    "\n",
    "### Używanie `nn.Sequential`\n",
    "\n",
    "PyTorch zapewnia wygodny sposób budowania takich sieci, w których tensor jest przekazywany sekwencyjnie przez operacje `nn.Sequential` ([dokumentacja](https://pytorch.org/docs/master/nn.html#torch.nn.Sequential )). Używaj jej do zbudowania równoważnej sieci: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (5): Softmax(dim=1)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x900 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 327,
       "width": 589
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hiperparametery sieci\n",
    "input_size = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "# Buduj feed-forward network\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.Softmax(dim=1))\n",
    "print(model)\n",
    "\n",
    "# Przekazywanie dalej przez sieć i wyświetlanie danych wyjściowych \n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "ps = model.forward(images[0,:])\n",
    "helper.view_classify(images[0].view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutaj nasz model jest taki sam jak poprzednio: 784 jednostki wejściowe, warstwa ukryta z 128 jednostkami, aktywacja ReLU, ukryta warstwa 64 jednostek, kolejne ReLU, następnie warstwa wyjściowa z 10 jednostkami i wyjście softmax.\n",
    "\n",
    "Operacje są dostępne po przekazaniu odpowiedniego indeksu. Na przykład, jeśli chcesz uzyskać pierwszą operację liniową i spojrzeć na wagi, użyjesz `model[0]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=128, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0026,  0.0080,  0.0260,  ...,  0.0217,  0.0317, -0.0096],\n",
       "        [ 0.0108,  0.0118, -0.0082,  ...,  0.0040, -0.0005,  0.0038],\n",
       "        [ 0.0108, -0.0025,  0.0052,  ..., -0.0143,  0.0148,  0.0338],\n",
       "        ...,\n",
       "        [-0.0324, -0.0356,  0.0314,  ...,  0.0274, -0.0233, -0.0136],\n",
       "        [-0.0095,  0.0325,  0.0225,  ...,  0.0056,  0.0022,  0.0118],\n",
       "        [-0.0028,  0.0075,  0.0171,  ..., -0.0240, -0.0354,  0.0122]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model[0])\n",
    "model[0].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możesz również przekazać `OrderedDict`, aby nazwać poszczególne warstwy i operacje, zamiast używać przyrostowych liczb całkowitych. Zauważ, że klucze słownika muszą być unikalne, więc _każda operacja musi mieć inną nazwę_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "model = nn.Sequential(OrderedDict([\n",
    "                      ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "                      ('relu1', nn.ReLU()),\n",
    "                      ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "                      ('relu2', nn.ReLU()),\n",
    "                      ('output', nn.Linear(hidden_sizes[1], output_size)),\n",
    "                      ('softmax', nn.Softmax(dim=1))]))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz możesz uzyskać dostęp do warstw za pomocą liczby całkowitej lub nazwy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=128, bias=True)\n",
      "Linear(in_features=784, out_features=128, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(model[0])\n",
    "print(model.fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trenowanie sieci neuronowej\n",
    "\n",
    "Sieć, którą zbudowaliśmy w poprzedniej części, nie jest tak sprytna, nie wie nic o naszych odręcznych cyfrach. Sieci neuronowe z nieliniowymi aktywacjami działają jak uniwersalne aproksymatory funkcji. Istnieje pewna funkcja, która mapuje dane wejściowe na dane wyjściowe. Na przykład obrazy odręcznych cyfr do prawdopodobieństw klas. Siła sieci neuronowych polega na tym, że możemy nauczyć je przybliżać tę funkcję i w zasadzie każdą funkcję, mając wystarczającą ilość danych i czasu obliczeniowego.\n",
    "\n",
    "<img src=\"assets/function_approx.png\" width=500px>\n",
    "\n",
    "Początkowo sieć jest naiwna, nie zna funkcji mapującej wejścia na wyjścia. Szkolimy sieć, pokazując jej przykłady z rzeczywistych danych, a następnie dostosowując parametry sieci tak, aby aproksymowała tę funkcję.\n",
    "\n",
    "Aby znaleźć te parametry, musimy wiedzieć, jak słabo sieć przewiduje rzeczywiste wyniki. W tym celu obliczamy **funkcję straty** (zwaną również kosztem), będącą miarą naszego błędu przewidywania. Na przykład średnia kwadratowa strata jest często używana w problemach regresji i klasyfikacji binarnej\n",
    "\n",
    "$$\n",
    "\\large \\ell = \\frac{1}{2n}\\sum_i^n{\\left(y_i - \\hat{y}_i\\right)^2},\n",
    "$$\n",
    "\n",
    "gdzie $n$ to liczba przykładów uczących, $y_i$ to etykiety prawdziwe, a $\\hat{y}_i$ to etykiety przewidywane.\n",
    "\n",
    "Minimalizując tę stratę w odniesieniu do parametrów sieci, możemy znaleźć konfiguracje, w których strata jest minimalna, a sieć jest w stanie przewidzieć prawidłowe etykiety z dużą dokładnością. Znajdujemy to minimum za pomocą procesu zwanego **spadkiem gradientu**. Gradient jest nachyleniem funkcji straty i wskazuje kierunek najszybszej zmiany. Aby w jak najkrótszym czasie dojść do minimum, chcemy podążać za gradientem (w dół). Można to potraktować jak zejście z góry, podążając po najbardziej stromym zboczu do podstawy.\n",
    "\n",
    "<img src='assets/gradient_descent.png' width=350px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propagacja wsteczna\n",
    "\n",
    "W przypadku sieci jednowarstwowych opadanie gradientowe jest proste do zaimplementowania. Jednak jest to bardziej skomplikowane w przypadku głębszych, wielowarstwowych sieci neuronowych, takich jak ta, którą zbudowaliśmy. Na tyle skomplikowane, że zanim naukowcy odkryli, jak trenować sieci wielowarstwowe, minęło około 30 lat.\n",
    "\n",
    "Uczenie sieci wielowarstwowych odbywa się poprzez **propagację wsteczną**, która w rzeczywistości jest tylko zastosowaniem reguły łańcucha z rachunku różniczkowego. Najłatwiej to zrozumieć, jeśli przekształcimy sieć dwuwarstwową w reprezentację graficzną.\n",
    "\n",
    "<img src='assets/backprop_diagram.png' width=550px>\n",
    "\n",
    "W przypadku przesyłania dalej przez sieć nasze dane i operacje przechodzą tutaj od dołu do góry. Przekazujemy dane wejściowe $x$ przez transformację liniową $L_1$ z wagami $W_1$ i obciążeniami $b_1$. Wyjście przechodzi następnie przez operację sigmoidalną $S$ i kolejną transformację liniową $L_2$. Na koniec obliczamy stratę $\\ell$. Stratę wykorzystujemy jako miarę tego, jak złe są prognozy sieci. Celem jest zatem takie dostosowanie wag i odchyleń, aby zminimalizować straty.\n",
    "\n",
    "Aby trenować wagi ze spadkiem gradientu, propagujemy gradient straty wstecz przez sieć. Każda operacja ma pewien gradient między wejściami i wyjściami. Gdy wysyłamy gradienty wstecz, mnożymy przychodzący gradient przez gradient dla operacji. Matematycznie jest to po prostu obliczenie gradientu straty w odniesieniu do wag przy użyciu reguły łańcucha.\n",
    "\n",
    "$$\n",
    "\\large \\frac{\\partial \\ell}{\\partial W_1} = \\frac{\\partial L_1}{\\partial W_1} \\frac{\\partial S}{\\partial L_1} \\frac{\\partial L_2}{\\partial S} \\frac{\\partial \\ell}{\\partial L_2}\n",
    "$$\n",
    "\n",
    "**Uwaga:** pomijam tutaj kilka szczegółów, które wymagają znajomości rachunku wektorowego, ale po każdy student powienie go znać.\n",
    "\n",
    "Aktualizujemy nasze wagi za pomocą tego gradientu z pewnym współczynnikiem uczenia się $\\alpha$.\n",
    "\n",
    "$$\n",
    "\\large W^\\prime_1 = W_1 - \\alpha \\frac{\\partial \\ell}{\\partial W_1}\n",
    "$$\n",
    "\n",
    "Szybkość uczenia $\\alpha$ jest ustawiona w taki sposób, że kroki aktualizacji wagi są na tyle małe, że metoda iteracyjna ustala się na minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funkcje straty w PyTorch\n",
    "\n",
    "Zacznijmy od tego, jak obliczamy stratę za pomocą PyTorch. Poprzez moduł `nn` PyTorch zapewnia straty, takie jak strata entropii krzyżowej (`nn.CrossEntropyLoss`). Zwykle zobaczysz stratę przypisaną do „kryterium”. Jak wspomniano w ostatniej części, w przypadku problemu z klasyfikacją, takiego jak MNIST, używamy funkcji softmax do przewidywania prawdopodobieństw klas. Z softmax na wyjściu, chcemyz użyć entropii krzyżowej jako funkcji straty. Aby faktycznie obliczyć stratę, najpierw definiujemy kryterium, a następnie przekazujesz dane wyjściowe swojej sieci i prawidłowe etykiety.\n",
    "\n",
    "Coś naprawdę ważnego do odnotowania tutaj. Patrząc na [dokumentację dla `nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss),\n",
    "\n",
    "> To kryterium łączy `nn.LogSoftmax()` i `nn.NLLLoss()` w jednej klasie.\n",
    ">\n",
    "> Oczekuje się, że dane wejściowe będą zawierać wyniki dla każdej klasy.\n",
    "\n",
    "Oznacza to, że musimy przekazać do strat surowe dane wyjściowe naszej sieci, a nie dane wyjściowe funkcji softmax. Te nieprzetworzone dane wyjściowe są zwykle nazywane *logitami* lub *scores*. Używamy logitów, ponieważ softmax daje prawdopodobieństwa, które często będą bardzo bliskie zeru lub jednego, ale liczby zmiennoprzecinkowe nie mogą dokładnie reprezentować wartości bliskich zeru lub jednego ([czytaj więcej tutaj](https://docs.python.org /3/tutorial/floatingpoint.html)). Zwykle najlepiej jest unikać wykonywania obliczeń z prawdopodobieństwami, zwykle używamy prawdopodobieństw logarytmicznych. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Zdefiniuj przekształcenia, aby znormalizować dane \n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5), (0.5)),\n",
    "                              ])\n",
    "# Pobierz i załaduj dane treningowe\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2954, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Budowa struktury sieć feed-forward \n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10))\n",
    "\n",
    "# Definicja funkcji straty\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Pobranie danych\n",
    "images, labels = next(iter(trainloader))\n",
    "# Spłaszczenie obrazów\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Przejście przez sieć \n",
    "logits = model(images)\n",
    "# Wyznaczenie błędu predykcji\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wygodniej jest zbudować model z wyjściem log-softmax za pomocą `nn.LogSoftmax` lub `F.log_softmax` ([dokumentacja](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html#torch.nn.Softmax)). Następnie możesz uzyskać rzeczywiste prawdopodobieństwa, biorąc funkcję wykładniczą `torch.exp(output)`. W przypadku danych wyjściowych log-softmax chcemy z reguły używać ujemnej straty logarytmowanego prawdopodobieństwa, `nn.NLLLoss` ([dokumentacja](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss)) .\n",
    "\n",
    ">**Ćwiczenie:** Zbuduj model, który jako wynik zwraca log-softmax i oblicz stratę przy użyciu ujemnego logarytmu strat prawdopodobieństwa. Zauważ, że dla `nn.LogSoftmax` i `F.log_softmax` musisz odpowiednio ustawić argument słowa kluczowego `dim`. `dim=0` oblicza softmax w wierszach, więc każda kolumna sumuje się do 1, podczas gdy `dim=1` oblicza w kolumnach, więc każdy wiersz sumuje się do 1. Zastanów się, jaki ma być wynik i wybierz odpowiednio `dim` . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0987, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Zbuduj sieć feed-forward \n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64,10),\n",
    "                      nn.Softmax(dim=1))\n",
    "\n",
    "# TODO: Zdefiniuj stratę \n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "### Uruchom, aby sprawdzić wyniki swojej pracy \n",
    "# Pobranie danych\n",
    "images, labels = next(iter(trainloader))\n",
    "# Spłaszczenie obrazów\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Przejście przez sieć \n",
    "logits = model(images)\n",
    "# Wyznaczenie błędu predykcji\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "\n",
    "Skoro już wiemy, jak obliczyć stratę, w jaki sposób możemy jej użyć do wykonania wstecznej propagacji błędów? Torch dostarcza moduł `autograd` do automatycznego obliczania gradientów tensorów. Możemy go użyć do obliczenia gradientów wszystkich naszych parametrów w odniesieniu do straty. Autograd działa, śledząc operacje wykonywane na tensorach, a następnie przechodząc wstecz przez te operacje, obliczając po drodze gradienty. Aby upewnić się, że PyTorch śledzi operacje na tensorze i oblicza gradienty, musisz ustawić `requires_grad = True` na tensorze. Możesz to zrobić podczas tworzenia za pomocą słowa kluczowego `requires_grad` lub w dowolnym momencie za pomocą `x.requires_grad_(True)`.\n",
    "\n",
    "Możesz wyłączyć gradienty dla bloku kodu z zawartością `torch.no_grad()`:\n",
    "```python\n",
    "x = torch.zeros(1, requires_grad=True)\n",
    ">>> with torch.no_grad():\n",
    "...     y = x * 2\n",
    ">>> y.requires_grad\n",
    "False\n",
    "```\n",
    "\n",
    "Możesz także włączać i wyłączać gradienty za pomocą `torch.set_grad_enabled(True|False)`.\n",
    "\n",
    "Gradienty są obliczane w odniesieniu do pewnej zmiennej `z` za pomocą `z.backward()`. To wykonuje wsteczne przejście przez operacje, które stworzyły `z`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2771,  1.2729],\n",
      "        [-0.3430,  0.4110]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0768, 1.6203],\n",
      "        [0.1176, 0.1689]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej widzimy operację, która utworzyła `y`, operację mocy `PowBackward0`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x7f4e91194be0>\n"
     ]
    }
   ],
   "source": [
    "## grad_fn pokazuje funkcję, która wygenerowała tą zmienną \n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moduł autogradu śledzi te operacje i wie, jak obliczyć gradient dla każdej z nich. W ten sposób jest w stanie obliczyć gradienty dla łańcucha operacji w odniesieniu do dowolnego tensora. Zredukujmy tensor `y` do wartości skalarnej, czyli średniej. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4959, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możesz sprawdzić gradienty dla `x` i `y`, ale obecnie są one puste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby obliczyć gradienty, musisz uruchomić metodę `.backward` na zmiennej, na przykład `z`. Spowoduje to obliczenie gradientu dla `z` w odniesieniu do `x`\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial x} = \\frac{\\partial}{\\partial x}\\left[\\frac{1}{n}\\sum_i^n x_i^2\\right] = \\frac{x }{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1386,  0.6365],\n",
      "        [-0.1715,  0.2055]])\n",
      "tensor([[ 0.1386,  0.6365],\n",
      "        [-0.1715,  0.2055]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Te obliczenia gradientów są szczególnie przydatne w przypadku sieci neuronowych. Do treningu potrzebujemy gradientów kosztów w odniesieniu do wag. Dzięki PyTorch przesyłamy dane do przodu przez sieć, aby obliczyć straty, a następnie cofamy się, aby obliczyć gradienty w odniesieniu do strat. Gdy mamy już gradienty, możemy wykonać krok w dół gradientu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strata i Autograd razem\n",
    "\n",
    "Kiedy tworzymy sieć za pomocą PyTorch, wszystkie parametry są inicjowane za pomocą `requires_grad = True`. Oznacza to, że kiedy obliczamy stratę i wywołujemy `loss.backward()`, obliczane są gradienty parametrów. Te gradienty są używane do aktualizacji wag za pomocą spadku gradientu. Poniżej możesz zobaczyć przykład obliczania gradientów za pomocą przejścia do tyłu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Budowanie sieci typu feed-forward\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logits = model(images)\n",
    "loss = criterion(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przed przejściem do tyłu: \n",
      " None\n",
      "Po przejściem do tyłu: \n",
      " tensor([[-0.0010, -0.0010, -0.0010,  ..., -0.0010, -0.0010, -0.0010],\n",
      "        [ 0.0013,  0.0013,  0.0013,  ...,  0.0013,  0.0013,  0.0013],\n",
      "        [-0.0009, -0.0009, -0.0009,  ..., -0.0009, -0.0009, -0.0009],\n",
      "        ...,\n",
      "        [ 0.0020,  0.0020,  0.0020,  ...,  0.0020,  0.0020,  0.0020],\n",
      "        [ 0.0003,  0.0003,  0.0003,  ...,  0.0003,  0.0003,  0.0003],\n",
      "        [ 0.0011,  0.0011,  0.0011,  ...,  0.0011,  0.0011,  0.0011]])\n"
     ]
    }
   ],
   "source": [
    "print('Przed przejściem do tyłu: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('Po przejściem do tyłu: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trenowanie sieci!\n",
    "\n",
    "Jest jeszcze ostatni element, którego potrzebujemy, aby rozpocząć trening, jest nim optymalizator, którego użyjemy do aktualizacji wag wraz z gradientami. Uzyskujemy je z [pakietu `optim`] (https://pytorch.org/docs/stable/optim.html) PyTorch. Na przykład możemy użyć gradientu stochastycznego z `optim.SGD`. Poniżej możesz zobaczyć, jak zdefiniować optymalizator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Optymalizator wymaga podania parametrów modelu oraz współczynnika uczenia\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz wiemy, jak korzystać ze wszystkich poszczególnych części, więc nadszedł czas, aby zobaczyć, jak ze sobą współpracują. Rozważmy tylko jeden krok uczenia się przed przejrzeniem wszystkich danych. Ogólny proces z PyTorch:\n",
    "\n",
    "* Wykonaj przejście do w przód sieci\n",
    "* Użyj danych wyjściowych, aby obliczyć straty\n",
    "* Wykonaj wsteczne przejście przez sieć za pomocą `loss.backward()`, aby obliczyć gradienty\n",
    "* Zrób krok z optymalizatorem, aby zaktualizować wagi\n",
    "\n",
    "Poniższy kod wykonuje jeden krok treningowy i wypisuje wagi oraz gradienty, po to by zobaczyć, jak się zmieniają. Zauważ, że mamy linijkę `optimizer.zero_grad()`. Kiedy wykonujemy wiele przejść wstecz z tymi samymi parametrami, gradienty są kumulowane. Oznacza to, że musisz wyzerować gradienty na każdym przejściu treningowym. W innym wypadku gradienty z poprzednich partii treningowych zostaną zachowane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicjacja wag -  Parameter containing:\n",
      "tensor([[ 2.4278e-02, -2.3785e-02,  9.2740e-03,  ..., -3.4949e-02,\n",
      "         -1.3039e-02,  2.8164e-02],\n",
      "        [ 5.5557e-03, -1.5828e-02,  2.4985e-02,  ...,  6.1103e-03,\n",
      "          2.7238e-02,  2.2511e-04],\n",
      "        [ 2.5185e-02,  3.0458e-02,  1.3974e-02,  ..., -3.3777e-02,\n",
      "         -5.7686e-03,  4.6649e-03],\n",
      "        ...,\n",
      "        [-1.0615e-02, -2.2955e-02,  1.4232e-02,  ...,  3.2308e-02,\n",
      "         -2.6906e-02, -1.1792e-02],\n",
      "        [-3.1567e-02,  2.9661e-02,  2.7743e-02,  ..., -7.1108e-03,\n",
      "          1.3121e-02,  1.9321e-02],\n",
      "        [ 1.3977e-02,  1.5875e-02, -9.6687e-05,  ...,  7.2223e-03,\n",
      "         -2.8970e-02,  1.0285e-02]], requires_grad=True)\n",
      "Gradient - tensor([[ 0.0012,  0.0012,  0.0012,  ...,  0.0012,  0.0012,  0.0012],\n",
      "        [ 0.0045,  0.0045,  0.0045,  ...,  0.0045,  0.0045,  0.0045],\n",
      "        [-0.0009, -0.0009, -0.0009,  ..., -0.0009, -0.0009, -0.0009],\n",
      "        ...,\n",
      "        [-0.0013, -0.0013, -0.0013,  ..., -0.0013, -0.0013, -0.0013],\n",
      "        [ 0.0025,  0.0025,  0.0025,  ...,  0.0025,  0.0025,  0.0025],\n",
      "        [-0.0009, -0.0009, -0.0009,  ..., -0.0009, -0.0009, -0.0009]])\n"
     ]
    }
   ],
   "source": [
    "print('Inicjacja wag - ', model[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "# Wyczyść gradienty, zrób to, ponieważ gradienty się kumulują \n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Przejście w przodu, następnie do tyłu i zaktualizacja wagi \n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradient -', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights -  Parameter containing:\n",
      "tensor([[ 2.4266e-02, -2.3797e-02,  9.2615e-03,  ..., -3.4961e-02,\n",
      "         -1.3052e-02,  2.8152e-02],\n",
      "        [ 5.5106e-03, -1.5873e-02,  2.4940e-02,  ...,  6.0652e-03,\n",
      "          2.7193e-02,  1.7998e-04],\n",
      "        [ 2.5194e-02,  3.0467e-02,  1.3982e-02,  ..., -3.3768e-02,\n",
      "         -5.7599e-03,  4.6736e-03],\n",
      "        ...,\n",
      "        [-1.0602e-02, -2.2943e-02,  1.4244e-02,  ...,  3.2320e-02,\n",
      "         -2.6893e-02, -1.1779e-02],\n",
      "        [-3.1592e-02,  2.9636e-02,  2.7718e-02,  ..., -7.1361e-03,\n",
      "          1.3096e-02,  1.9296e-02],\n",
      "        [ 1.3986e-02,  1.5884e-02, -8.7754e-05,  ...,  7.2312e-03,\n",
      "         -2.8961e-02,  1.0294e-02]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Wykonaj krok aktualizacji i dodaj kilka nowych wag\n",
    "optimizer.step()\n",
    "print('Updated weights - ', model[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pełny trening\n",
    "\n",
    "Teraz umieścimy ten algorytm w pętli, dzięki czemu będziemy mogli przejrzeć wszystkie obrazy. Przejście przez cały zbiór danych nazywana jest *epoką*. Więc tutaj przejdziemy przez `trainloader`, aby uzyskać nasze partie treningowe. Dla każdej partii wykonamy przebieg treningowy, w którym obliczymy stratę, wykonamy przejście wstecz i zaktualizujemy wagi.\n",
    "\n",
    ">**Ćwiczenie:** Implementuj szkolenie naszej sieci. Przy poprawnej implementacji, powinieneś zaobserwować spadek strat treningowych z każdą epoką. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.897002504324354\n",
      "Training loss: 0.8682981986544533\n",
      "Training loss: 0.5352280606656695\n",
      "Training loss: 0.4357164472595715\n",
      "Training loss: 0.38963346567743623\n"
     ]
    }
   ],
   "source": [
    "## Miejsce na rozwiązanie\n",
    "\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Spłaszcz obrazy MNIST do wektora o długości 784 \n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        \n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po wytrenowaniu sieci możemy sprawdzić jej prognozy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x900 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Wyłącz gradienty, aby przyspieszyć tę część \n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Dane wyjściowe sieci to logarytmiczne prawdopodobieństwa,\n",
    "# Prawdopodobieństw należy wyznaczyć przy pomocy funkcji wykładniczej  \n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz nasza sieć potrafi dokładnie przewidzieć cyfry na naszych obrazach. Na kolejnych zajęciach napiszemy kod do trenowania sieci neuronowej na bardziej złożonym zbiorze danych. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
